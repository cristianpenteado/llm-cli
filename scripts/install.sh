#!/bin/bash

# LLM CLI - Script de InstalaÃ§Ã£o
# Este script instala a LLM CLI e suas dependÃªncias

set -e

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# FunÃ§Ã£o para logging
log() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Verificar se Ã© Linux
if [[ "$OSTYPE" != "linux-gnu"* ]]; then
    error "Este script Ã© destinado apenas para sistemas Linux"
    exit 1
fi

# Verificar se Ã© executado como root
if [[ $EUID -eq 0 ]]; then
    error "NÃ£o execute este script como root"
    exit 1
fi

log "ğŸš€ Iniciando instalaÃ§Ã£o da LLM CLI..."

# Verificar Node.js
log "ğŸ“‹ Verificando Node.js..."
if ! command -v node &> /dev/null; then
    error "Node.js nÃ£o encontrado. Instalando..."
    
    # Detectar distribuiÃ§Ã£o Linux
    if command -v apt-get &> /dev/null; then
        # Ubuntu/Debian
        curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
        sudo apt-get install -y nodejs
    elif command -v yum &> /dev/null; then
        # CentOS/RHEL
        curl -fsSL https://rpm.nodesource.com/setup_18.x | sudo bash -
        sudo yum install -y nodejs
    elif command -v dnf &> /dev/null; then
        # Fedora
        curl -fsSL https://rpm.nodesource.com/setup_18.x | sudo bash -
        sudo dnf install -y nodejs
    else
        error "DistribuiÃ§Ã£o Linux nÃ£o suportada. Instale Node.js manualmente: https://nodejs.org/"
        exit 1
    fi
else
    NODE_VERSION=$(node --version | cut -d'v' -f2 | cut -d'.' -f1)
    if [[ $NODE_VERSION -lt 18 ]]; then
        error "Node.js versÃ£o 18+ Ã© requerida. VersÃ£o atual: $(node --version)"
        exit 1
    fi
    success "Node.js $(node --version) encontrado"
fi

# Verificar npm
log "ğŸ“¦ Verificando npm..."
if ! command -v npm &> /dev/null; then
    error "npm nÃ£o encontrado"
    exit 1
fi
success "npm $(npm --version) encontrado"

# Instalar dependÃªncias do sistema
log "ğŸ”§ Instalando dependÃªncias do sistema..."
if command -v apt-get &> /dev/null; then
    sudo apt-get update
    sudo apt-get install -y curl wget git build-essential
elif command -v yum &> /dev/null; then
    sudo yum install -y curl wget git gcc gcc-c++ make
elif command -v dnf &> /dev/null; then
    sudo dnf install -y curl wget git gcc gcc-c++ make
fi

# Verificar se o Vlama estÃ¡ instalado
log "ğŸ¤– Verificando Vlama..."
if ! command -v vlama &> /dev/null; then
    warn "Vlama nÃ£o encontrado. Instalando..."
    
    # Tentar instalar Vlama
    if curl -fsSL https://get.vlama.ai | sh; then
        success "Vlama instalado com sucesso"
    else
        warn "Falha na instalaÃ§Ã£o automÃ¡tica do Vlama"
        log "Instale manualmente: https://vlama.ai"
    fi
else
    success "Vlama encontrado"
fi

# Instalar LLM CLI globalmente
log "ğŸ“¥ Instalando LLM CLI..."
if npm install -g llm-cli; then
    success "LLM CLI instalada com sucesso"
else
    error "Falha ao instalar LLM CLI"
    exit 1
fi

# Verificar instalaÃ§Ã£o
log "âœ… Verificando instalaÃ§Ã£o..."
if command -v llm &> /dev/null; then
    success "LLM CLI instalada e disponÃ­vel como 'llm'"
    llm --version
else
    error "LLM CLI nÃ£o foi instalada corretamente"
    exit 1
fi

# Criar diretÃ³rio de configuraÃ§Ã£o
log "âš™ï¸ Configurando diretÃ³rio de configuraÃ§Ã£o..."
mkdir -p ~/.llm-cli
success "DiretÃ³rio de configuraÃ§Ã£o criado: ~/.llm-cli"

# ConfiguraÃ§Ã£o inicial
log "ğŸ”§ Executando configuraÃ§Ã£o inicial..."
if llm detect-hardware; then
    success "ConfiguraÃ§Ã£o inicial concluÃ­da"
else
    warn "ConfiguraÃ§Ã£o inicial falhou. Execute 'llm detect-hardware' manualmente"
fi

# Mostrar prÃ³ximos passos
echo ""
success "ğŸ‰ InstalaÃ§Ã£o concluÃ­da com sucesso!"
echo ""
log "ğŸ“š PrÃ³ximos passos:"
echo "  1. Execute 'llm detect-hardware' para configurar seu sistema"
echo "  2. Execute 'llm set-default-model <modelo>' para definir modelo padrÃ£o"
echo "  3. Navegue para um projeto e execute 'llm init'"
echo "  4. Use 'llm chat' para iniciar modo conversacional"
echo ""
log "ğŸ“– DocumentaÃ§Ã£o: https://github.com/llm-cli/llm-cli"
log "ğŸ› Problemas: https://github.com/llm-cli/llm-cli/issues"
echo ""
success "ğŸš€ Boa codificaÃ§Ã£o com LLM CLI!"
