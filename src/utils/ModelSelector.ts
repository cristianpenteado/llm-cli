import inquirer from 'inquirer';
import cliProgress from 'cli-progress';
import ora from 'ora';
import { Logger } from './Logger';
import { OllamaManager } from '../ollama/OllamaManager';
import { ModelConfig } from '../types';

export interface SuggestedModel {
  name: string;
  description: string;
  size: string;
  recommended: boolean;
  category: 'coding' | 'general' | 'quantized';
}

export class ModelSelector {
  private ollamaManager: OllamaManager;

  constructor(ollamaManager: OllamaManager) {
    this.ollamaManager = ollamaManager;
  }

  /**
   * Lista de modelos sugeridos padr√£o
   */
  private getSuggestedModels(): SuggestedModel[] {
    return [
      {
        name: 'deepseek-coder:6.7b',
        description: 'Modelo especializado em c√≥digo, excelente para desenvolvimento',
        size: '~6.7GB',
        recommended: true,
        category: 'coding'
      },
      {
        name: 'qwen2.5-coder:7b',
        description: 'Modelo de c√≥digo da Alibaba, bom equil√≠brio performance/tamanho',
        size: '~7GB',
        recommended: true,
        category: 'coding'
      },
      {
        name: 'deepseek-coder-v2-lite:16b',
        description: 'Vers√£o lite do DeepSeek Coder V2, mais r√°pido',
        size: '~16GB',
        recommended: false,
        category: 'coding'
      },
      {
        name: 'codellama:13b',
        description: 'Code LLaMA 13B, excelente para c√≥digo complexo',
        size: '~13GB',
        recommended: true,
        category: 'coding'
      },
      {
        name: 'phi-3-mini:3.8b',
        description: 'Phi-3 Mini, modelo compacto e eficiente',
        size: '~3.8GB',
        recommended: true,
        category: 'general'
      },
      {
        name: 'mistral-codestral:7b',
        description: 'Mistral especializado em c√≥digo',
        size: '~7GB',
        recommended: false,
        category: 'coding'
      },
      {
        name: 'llama3.1:8b',
        description: 'LLaMA 3.1 8B, modelo geral vers√°til',
        size: '~8GB',
        recommended: false,
        category: 'general'
      },
      {
        name: 'codegemma:7b',
        description: 'CodeGemma da Google, especializado em c√≥digo',
        size: '~7GB',
        recommended: false,
        category: 'coding'
      },
      {
        name: 'ode-llama:13b',
        description: 'OdeLLaMA 13B quantizado Q4_K_M, otimizado para c√≥digo',
        size: '~13GB',
        recommended: true,
        category: 'coding'
      },
      {
        name: 'mistral-codestral:7b',
        description: 'Mistral Codestral 7B, especializado em desenvolvimento',
        size: '~7GB',
        recommended: false,
        category: 'coding'
      }
    ];
  }

  /**
   * Seleciona modelo interativamente
   */
  async selectModel(): Promise<string> {
    Logger.info('ü§ñ Sele√ß√£o de Modelo LLM');
    Logger.info('Escolha uma op√ß√£o para seu projeto:');
    Logger.newline();

    // Obter modelos dispon√≠veis no Ollama
    const availableModels = await this.ollamaManager.listModels();
    const availableModelNames = availableModels.map(m => m.name);

    // Filtrar modelos sugeridos que est√£o dispon√≠veis
    const suggestedModels = this.getSuggestedModels();
    const availableSuggested = suggestedModels.filter(model => 
      availableModelNames.includes(model.name)
    );

    // Modelos dispon√≠veis mas n√£o na lista sugerida
    const otherAvailable = availableModels.filter(model => 
      !suggestedModels.some(s => s.name === model.name)
    );

    // Criar op√ß√µes para o inquirer
    const choices = [];

    // Adicionar op√ß√£o de setup completo
    choices.push(new inquirer.Separator('üöÄ SETUP COMPLETO'));
    choices.push({
      name: 'üöÄ Setup Completo - Selecionar e baixar modelos',
      value: 'setup_complete'
    });

    // Adicionar modelos sugeridos dispon√≠veis
    if (availableSuggested.length > 0) {
      choices.push(new inquirer.Separator('‚úÖ MODELOS DISPON√çVEIS'));
      availableSuggested.forEach(model => {
        choices.push({
          name: `${model.name} - ${model.description} (${model.size})`,
          value: model.name,
          short: model.name
        });
      });
    }

    // Adicionar outros modelos dispon√≠veis
    if (otherAvailable.length > 0) {
      choices.push(new inquirer.Separator('üìö OUTROS MODELOS'));
      otherAvailable.forEach(model => {
        choices.push({
          name: `${model.name} - ${model.description} (${model.size})`,
          value: model.name,
          short: model.name
        });
      });
    }

    // Adicionar op√ß√£o para baixar modelo
    choices.push(new inquirer.Separator('üì• BAIXAR MODELO'));
    choices.push({
      name: 'üì• Baixar modelo espec√≠fico...',
      value: 'download'
    });

    // Adicionar op√ß√£o para digitar nome manualmente
    choices.push({
      name: '‚úèÔ∏è Digitar nome do modelo...',
      value: 'manual'
    });

    const { selectedModel } = await inquirer.prompt([
      {
        type: 'list',
        name: 'selectedModel',
        message: 'Escolha uma op√ß√£o:',
        choices: choices,
        pageSize: 12
      }
    ]);

    if (selectedModel === 'setup_complete') {
      return await this.handleSetupComplete();
    } else if (selectedModel === 'download') {
      return await this.handleModelDownload();
    } else if (selectedModel === 'manual') {
      return await this.handleManualModelInput();
    }

    return selectedModel;
  }

  /**
   * Gerencia setup completo autom√°tico
   */
  private async handleSetupComplete(): Promise<string> {
    Logger.info('üöÄ Setup Completo - Sele√ß√£o de Modelos');
    Logger.info('Escolha quais modelos deseja baixar:');
    Logger.newline();

    const availableModels = [
      {
        name: 'deepseek-coder:6.7b',
        description: 'Modelo especializado em c√≥digo, excelente para desenvolvimento',
        size: '~6.7GB',
        recommended: true
      },
      {
        name: 'qwen2.5-coder:7b',
        description: 'Modelo de c√≥digo da Alibaba, bom equil√≠brio performance/tamanho',
        size: '~7GB',
        recommended: true
      },
      {
        name: 'deepseek-coder-v2-lite:16b',
        description: 'Vers√£o lite do DeepSeek Coder V2, mais r√°pido',
        size: '~16GB',
        recommended: false
      },
      {
        name: 'ode-llama:13b',
        description: 'OdeLLaMA 13B quantizado Q4_K_M, otimizado para c√≥digo',
        size: '~13GB',
        recommended: true
      },
      {
        name: 'phi-3-mini:3.8b',
        description: 'Phi-3 Mini, modelo compacto e eficiente',
        size: '~3.8GB',
        recommended: true
      },
      {
        name: 'mistral-codestral:7b',
        description: 'Mistral especializado em c√≥digo',
        size: '~7GB',
        recommended: false
      },
      {
        name: 'llama3.1:8b',
        description: 'LLaMA 3.1 8B, modelo geral vers√°til',
        size: '~8GB',
        recommended: false
      },
      {
        name: 'codegemma:7b',
        description: 'CodeGemma da Google, especializado em c√≥digo',
        size: '~7GB',
        recommended: false
      },
      {
        name: 'codellama:13b',
        description: 'Code LLaMA 13B, excelente para c√≥digo complexo',
        size: '~13GB',
        recommended: true
      }
    ];

    const { selectedModels } = await inquirer.prompt([
      {
        type: 'checkbox',
        name: 'selectedModels',
        message: 'Selecione os modelos que deseja baixar:',
        choices: availableModels.map(model => ({
          name: `${model.name} - ${model.description} (${model.size})${model.recommended ? ' [RECOMENDADO]' : ''}`,
          value: model.name,
          checked: model.recommended
        })),
        pageSize: 15
      }
    ]);

    if (selectedModels.length === 0) {
      Logger.warn('‚ö†Ô∏è Nenhum modelo selecionado. Voltando para sele√ß√£o manual...');
      return await this.selectModel();
    }

    Logger.info(`üöÄ Iniciando download de ${selectedModels.length} modelos...`);
    Logger.newline();

    // Criar barra de progresso m√∫ltipla
    const multibar = new cliProgress.MultiBar({
      clearOnComplete: false,
      hideCursor: true,
      format: ' {bar} | {model} | {percentage}% | {status}'
    }, cliProgress.Presets.shades_classic);

    const downloadedModels: string[] = [];
    const failedModels: string[] = [];

    // Criar barras de progresso para cada modelo
    const progressBars = selectedModels.map((modelName: string) => {
      return multibar.create(100, 0, {
        model: modelName.padEnd(25),
        status: 'Iniciando...',
        percentage: '0%'
      });
    });

    // Download em paralelo com progresso simulado
    const downloadPromises = selectedModels.map(async (modelName: string, index: number) => {
      const progressBar = progressBars[index];
      
      try {
        // Simular progresso durante o download
        let progress = 0;
        const progressInterval = setInterval(() => {
          progress += Math.random() * 15;
          if (progress > 90) progress = 90;
          
          progressBar.update(progress, {
            status: 'Baixando...',
            percentage: `${Math.round(progress)}%`
          });
        }, 500);

        // Fazer o download real
        await this.ollamaManager.downloadModel(modelName);
        
        clearInterval(progressInterval);
        progressBar.update(100, {
          status: '‚úÖ Conclu√≠do',
          percentage: '100%'
        });
        
        downloadedModels.push(modelName);
        
      } catch (error) {
        progressBar.update(100, {
          status: '‚ùå Erro',
          percentage: '100%'
        });
        failedModels.push(modelName);
        Logger.error(`‚ùå Erro ao baixar ${modelName}:`, error);
      }
    });

    // Aguardar todos os downloads
    await Promise.all(downloadPromises);
    
    // Fechar barras de progresso
    multibar.stop();

    Logger.newline();
    if (downloadedModels.length > 0) {
      Logger.success(`‚úÖ Download conclu√≠do! ${downloadedModels.length} modelos baixados.`);
      Logger.info('üìã Modelos baixados:');
      downloadedModels.forEach(model => Logger.info(`  ‚úÖ ${model}`));
    }

    if (failedModels.length > 0) {
      Logger.warn(`‚ö†Ô∏è ${failedModels.length} modelos falharam no download:`);
      failedModels.forEach(model => Logger.warn(`  ‚ùå ${model}`));
    }

    // Sugerir o primeiro modelo baixado como padr√£o
    if (downloadedModels.length > 0) {
      const recommendedModel = downloadedModels[0];
      Logger.info(`üí° Recomendamos usar: ${recommendedModel}`);
      
      const { useRecommended } = await inquirer.prompt([
        {
          type: 'confirm',
          name: 'useRecommended',
          message: `Deseja usar ${recommendedModel} como modelo padr√£o?`,
          default: true
        }
      ]);

      if (useRecommended) {
        return recommendedModel;
      }
    }

    // Se n√£o quiser usar o recomendado, voltar para sele√ß√£o
    Logger.info('üîÑ Escolha um modelo dos dispon√≠veis:');
    return await this.selectModel();
  }

  /**
   * Gerencia download de modelo
   */
  private async handleModelDownload(): Promise<string> {
    Logger.info('üì• Download de Modelo');
    Logger.info('Modelos populares para desenvolvimento:');
    Logger.newline();

    const popularModels = [
      'deepseek-coder:6.7b',
      'qwen2.5-coder:7b',
      'deepseek-coder-v2-lite:16b',
      'ode-llama:13b',
      'phi-3-mini:3.8b',
      'mistral-codestral:7b',
      'llama3.1:8b',
      'codegemma:7b',
      'codellama:13b'
    ];

    const { modelToDownload } = await inquirer.prompt([
      {
        type: 'list',
        name: 'modelToDownload',
        message: 'Qual modelo deseja baixar?',
        choices: [
          ...popularModels.map(name => ({
            name: name,
            value: name
          })),
          new inquirer.Separator(''),
          {
            name: '‚úèÔ∏è Digitar nome personalizado...',
            value: 'custom'
          }
        ]
      }
    ]);

    if (modelToDownload === 'custom') {
      const { customModelName } = await inquirer.prompt([
        {
          type: 'input',
          name: 'customModelName',
          message: 'Digite o nome do modelo (ex: llama2:7b):',
          validate: (input: string) => {
            if (input.trim().length === 0) {
              return 'Nome do modelo √© obrigat√≥rio';
            }
            return true;
          }
        }
      ]);
      return await this.downloadAndReturnModel(customModelName);
    }

    return await this.downloadAndReturnModel(modelToDownload);
  }

  /**
   * Gerencia input manual de modelo
   */
  private async handleManualModelInput(): Promise<string> {
    const { manualModelName } = await inquirer.prompt([
      {
        type: 'input',
        name: 'manualModelName',
        message: 'Digite o nome do modelo:',
        validate: (input: string) => {
          if (input.trim().length === 0) {
            return 'Nome do modelo √© obrigat√≥rio';
          }
          return true;
        }
      }
    ]);

    // Verificar se o modelo est√° dispon√≠vel
    const availableModels = await this.ollamaManager.listModels();
    const modelExists = availableModels.some(m => m.name === manualModelName);

    if (!modelExists) {
      Logger.warn(`‚ö†Ô∏è Modelo "${manualModelName}" n√£o encontrado localmente.`);
      
      const { shouldDownload } = await inquirer.prompt([
        {
          type: 'confirm',
          name: 'shouldDownload',
          message: `Deseja baixar o modelo "${manualModelName}"?`,
          default: true
        }
      ]);

      if (shouldDownload) {
        return await this.downloadAndReturnModel(manualModelName);
      } else {
        // Tentar novamente
        return await this.handleManualModelInput();
      }
    }

    return manualModelName;
  }

  /**
   * Faz download do modelo e retorna o nome
   */
  private async downloadAndReturnModel(modelName: string): Promise<string> {
    try {
      Logger.info(`üì• Iniciando download do modelo ${modelName}...`);
      
      // Criar barra de progresso
      const progressBar = new cliProgress.SingleBar({
        format: ' {bar} | {model} | {percentage}% | {status}',
        barCompleteChar: '\u2588',
        barIncompleteChar: '\u2591',
        hideCursor: true
      }, cliProgress.Presets.shades_classic);

      progressBar.start(100, 0, {
        model: modelName.padEnd(25),
        status: 'Iniciando...',
        percentage: '0%'
      });

      // Simular progresso durante o download
      let progress = 0;
      const progressInterval = setInterval(() => {
        progress += Math.random() * 15;
        if (progress > 90) progress = 90;
        
        progressBar.update(progress, {
          status: 'Baixando...',
          percentage: `${Math.round(progress)}%`
        });
      }, 500);

      // Fazer o download real
      await this.ollamaManager.downloadModel(modelName);
      
      clearInterval(progressInterval);
      progressBar.update(100, {
        status: '‚úÖ Conclu√≠do',
        percentage: '100%'
      });
      
      progressBar.stop();
      Logger.success(`‚úÖ Modelo ${modelName} baixado com sucesso!`);
      return modelName;
      
    } catch (error) {
      Logger.error(`‚ùå Erro ao baixar modelo ${modelName}:`, error);
      
      const { retry } = await inquirer.prompt([
        {
          type: 'confirm',
          name: 'retry',
          message: 'Deseja tentar novamente ou escolher outro modelo?',
          default: false
        }
      ]);

      if (retry) {
        return await this.handleModelDownload();
      } else {
        return await this.selectModel();
      }
    }
  }

  /**
   * Verifica se modelo est√° dispon√≠vel e sugere alternativas
   */
  async ensureModelAvailable(modelName: string): Promise<string> {
    const availableModels = await this.ollamaManager.listModels();
    const modelExists = availableModels.some(m => m.name === modelName);

    if (modelExists) {
      return modelName;
    }

    Logger.warn(`‚ö†Ô∏è Modelo "${modelName}" n√£o encontrado.`);
    Logger.info('üí° Modelos dispon√≠veis:');
    
    availableModels.forEach((model, index) => {
      Logger.info(`  ${index + 1}. ${model.name} (${model.size})`);
    });

    const { useAvailable } = await inquirer.prompt([
      {
        type: 'confirm',
        name: 'useAvailable',
        message: 'Deseja escolher um dos modelos dispon√≠veis?',
        default: true
      }
    ]);

    if (useAvailable) {
      return await this.selectModel();
    } else {
      // Tentar baixar o modelo original
      return await this.downloadAndReturnModel(modelName);
    }
  }
}
