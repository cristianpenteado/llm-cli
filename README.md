# LLM-CLI - Assistente de IA Conversacional

> **Chat Inteligente para Desenvolvimento** - Converse naturalmente, implemente automaticamente â¤ï¸

## ğŸš€ CaracterÃ­sticas Principais

- ğŸ’¬ **Chat Conversacional**: Fale naturalmente, sem comandos especiais
- ğŸ¯ **DetecÃ§Ã£o AutomÃ¡tica**: Detecta quando vocÃª quer implementar algo
- ğŸ“‹ **Planejamento Inteligente**: Cria planos automaticamente e executa com confirmaÃ§Ã£o
- âš¡ **SugestÃ£o de Comandos**: Sugere e executa comandos do sistema com sua aprovaÃ§Ã£o
- ğŸ¤– **Agente IA AvanÃ§ado**: Similar ao Claude Code, capaz de Q&A, planejamento e geraÃ§Ã£o de cÃ³digo
- ğŸ”§ **IntegraÃ§Ã£o Direta Ollama**: ComunicaÃ§Ã£o REST eficiente (sem overhead MCP)
- ğŸ—ï¸ **Arquitetura DDD**: Clean Code com domÃ­nios bem definidos
- ğŸ§ª **Testes Completos**: 14/14 testes passando

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Node.js 18+
- Ollama instalado e rodando na porta 11434
- Modelos Ollama (ex: `llama3.2`, `qwen2.5:7b`)

### InstalaÃ§Ã£o

```bash
git clone https://github.com/cristianpenteado/llm-cli.git
cd llm-cli
npm install
npm run build
npm link
```

## ğŸ¯ Como Usar

### Iniciar Chat Conversacional

```bash
# Iniciar chat interativo
llm
```

### Exemplos de Conversa Natural

```bash
# Perguntas conceituais
"Como funciona JWT?"
"Explique o padrÃ£o Repository"
"Qual a diferenÃ§a entre REST e GraphQL?"

# ImplementaÃ§Ãµes (detecta automaticamente)
"Quero criar uma API REST com Express"
"Implementa autenticaÃ§Ã£o no meu projeto"
"Fazer um sistema de login completo"
"Configurar TypeScript no projeto"
```

### Comandos BÃ¡sicos (apenas 3!)

- `help` - Mostra como usar
- `clear` - Limpa tela
- `exit` - Sair

**Tudo mais Ã© conversa natural!**

### Exemplo de Fluxo Conversacional

```bash
$ llm
ğŸ¤– LLM-CLI - Assistente de IA para Desenvolvimento

> Quero criar um sistema de autenticaÃ§Ã£o completo

ğŸ¤” Processando...
ğŸ’¬ Resposta: Vou criar um sistema de autenticaÃ§Ã£o JWT completo para vocÃª...

ğŸ¯ Detectei uma solicitaÃ§Ã£o de implementaÃ§Ã£o!
â“ Quer que eu crie um plano detalhado para isso? [s/n]: s

âœ… Plano criado: Sistema de AutenticaÃ§Ã£o JWT
ğŸ“ Passos:
  â–¶ï¸ 1. Setup inicial do projeto
     Configurar estrutura base com Express e TypeScript
  â¸ï¸ 2. Implementar middleware de autenticaÃ§Ã£o
     Criar middleware JWT para validaÃ§Ã£o de tokens
  â¸ï¸ 3. Criar rotas de auth
     Implementar login, registro e refresh token

â“ Executar o plano agora? [s/n]: s

ğŸš€ Executando plano...
ğŸ“ Passo 1: Setup inicial do projeto
Executar este passo? [sim/skip/stop]: sim
âœ… Passo concluÃ­do

> Como funciona JWT?

ğŸ’¬ Resposta: JWT (JSON Web Token) Ã© um padrÃ£o para transmitir informaÃ§Ãµes...
[ExplicaÃ§Ã£o detalhada]
```

## âš™ï¸ ConfiguraÃ§Ã£o

Arquivo de configuraÃ§Ã£o em `~/.llm-cli/config.yaml`:

```yaml
model:
  defaultModel: "llama3.2"
  temperature: 0.7
  maxTokens: 4096
  fallbackModels: ["llama3.2:1b", "qwen2.5:7b"]

agent:
  name: "Claude Code Assistant"
  personality: "helpful"  # helpful|concise|detailed|creative
  autoConfirm: false
  maxPlanSteps: 10
  contextWindow: 8192

cli:
  theme: "auto"  # dark|light|auto
  showTimestamps: false
  logLevel: "info"  # error|warn|info|debug
  historySize: 100

ollama:
  host: "localhost"
  port: 11434
  timeout: 30000
  retryAttempts: 3
  keepAlive: "5m"
```

## ğŸ—ï¸ Arquitetura

### Estrutura DDD

```
src/
â”œâ”€â”€ domain/                    # DomÃ­nio (regras de negÃ³cio)
â”‚   â”œâ”€â”€ agent/                # DomÃ­nio do agente IA
â”‚   â”‚   â””â”€â”€ Agent.ts         # Interfaces do agente
â”‚   â”œâ”€â”€ communication/        # DomÃ­nio de comunicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ ModelProvider.ts # Interface do provedor de modelo
â”‚   â””â”€â”€ configuration/        # DomÃ­nio de configuraÃ§Ã£o
â”‚       â””â”€â”€ Configuration.ts # Interfaces de config
â”œâ”€â”€ application/              # Camada de aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ services/            # ServiÃ§os de aplicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ AgentService.ts  # ImplementaÃ§Ã£o do agente
â”‚   â””â”€â”€ ports/               # Portas (interfaces)
â”‚       â”œâ”€â”€ FileSystemService.ts
â”‚       â””â”€â”€ Logger.ts
â”œâ”€â”€ infrastructure/          # Infraestrutura
â”‚   â”œâ”€â”€ cli/                # Interface CLI
â”‚   â”‚   â””â”€â”€ CLI.ts          # CLI interativo
â”‚   â”œâ”€â”€ ollama/             # IntegraÃ§Ã£o Ollama
â”‚   â”‚   â””â”€â”€ OllamaProvider.ts
â”‚   â”œâ”€â”€ filesystem/         # Sistema de arquivos
â”‚   â”œâ”€â”€ logging/           # Sistema de logs
â”‚   â”œâ”€â”€ configuration/     # RepositÃ³rio de config
â”‚   â””â”€â”€ di/               # InjeÃ§Ã£o de dependÃªncia
â”‚       â””â”€â”€ Container.ts   # Container DI
â””â”€â”€ __tests__/            # Testes
    â”œâ”€â”€ unit/            # Testes unitÃ¡rios
    â””â”€â”€ integration/     # Testes de integraÃ§Ã£o
```

### Fluxo de ComunicaÃ§Ã£o

```
CLI â†’ AgentService â†’ OllamaProvider â†’ Ollama API (REST)
```

**Por que nÃ£o MCP?** Para ambiente local, comunicaÃ§Ã£o direta via REST Ã© mais simples, eficiente e confiÃ¡vel que protocolos complexos.

## ğŸ“š DocumentaÃ§Ã£o Completa

- **[Guia Conversacional](docs/CONVERSATIONAL-GUIDE.md)** - Como conversar com o assistente
- **[Arquitetura](docs/ARCHITECTURE.md)** - Design tÃ©cnico e decisÃµes arquiteturais  
- **[Changelog](docs/CHANGELOG.md)** - HistÃ³rico completo de mudanÃ§as

## ğŸ§ª Desenvolvimento

### Setup

```bash
npm install
npm run dev     # Desenvolvimento
npm run build   # Build produÃ§Ã£o
npm test        # Executar testes
npm run test:watch  # Testes em watch mode
```

### Testes

```bash
# Todos os testes
npm test

# Testes especÃ­ficos
npm test -- AgentService
npm test -- OllamaProvider

# Coverage
npm test -- --coverage
```

### Estrutura de Testes

- **Unit Tests**: Testam componentes isoladamente
- **Integration Tests**: Testam fluxo completo CLI â†’ Agent â†’ Ollama
- **Mocks**: Simulam dependÃªncias externas (Ollama API, filesystem)

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie branch: `git checkout -b feature/nova-funcionalidade`
3. Commit: `git commit -m 'Add nova funcionalidade'`
4. Push: `git push origin feature/nova-funcionalidade`
5. Abra Pull Request

## ğŸ“„ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

- ğŸ› **Issues**: [GitHub Issues](https://github.com/cristianpenteado/llm-cli/issues)
- ğŸ’¬ **DiscussÃµes**: [GitHub Discussions](https://github.com/cristianpenteado/llm-cli/discussions)
- ğŸ“§ **Email**: cristian.penteado@gmail.com