# Exemplos de Uso da LLM CLI

Este arquivo cont√©m exemplos pr√°ticos de como usar a LLM CLI em diferentes cen√°rios de desenvolvimento.

## üöÄ Configura√ß√£o Inicial

### 1. Detectar Hardware e Configurar
```bash
# Detectar hardware do sistema
llm detect-hardware

# Sa√≠da esperada:
# üìä Hardware detectado:
#   CPU: Intel(R) Core(TM) i7-10700K CPU @ 3.80GHz (8 cores)
#   RAM: 32GB
#   GPU: NVIDIA GeForce RTX 3070 (8GB)
# 
# üöÄ Modelos recomendados:
#   1. deepseek-coder:6.7b-instruct - Modelo de c√≥digo especializado
#   2. phi-3:3.8b-instruct - Modelo compacto e eficiente
#   3. codellama:7b-instruct - Modelo especializado em c√≥digo

# Definir modelo padr√£o
llm set-default-model deepseek-coder:6.7b-instruct
```

### 2. Inicializar Primeiro Projeto
```bash
# Navegar para pasta do projeto
cd ~/projetos/meu-app-react

# Inicializar projeto (detecta TypeScript + React automaticamente)
llm init

# Sa√≠da esperada:
# üöÄ Inicializando novo projeto...
# üîç Primeira execu√ß√£o detectada. Analisando hardware...
# üí° Modelos recomendados para seu hardware:
#   1. deepseek-coder:6.7b-instruct - Modelo de c√≥digo especializado
# ‚úÖ Projeto inicializado em: /home/user/projetos/meu-app-react
# üìÅ Estrutura do projeto: TypeScript/React
# ü§ñ Modelo configurado: deepseek-coder:6.7b-instruct
```

## üí¨ Modo Conversacional

### 3. Iniciar Chat com IA
```bash
# Iniciar modo conversacional
llm chat

# Sa√≠da esperada:
# üí¨ Iniciando modo conversacional...
# ü§ñ Conectado ao modelo: deepseek-coder:6.7b-instruct
# üí° Digite suas perguntas ou comandos. Use /help para ver comandos dispon√≠veis.
# ü§ñ > 
```

### 4. Comandos de Chat Dispon√≠veis
```bash
# No modo conversacional, digite:
/help                    # Mostra todos os comandos dispon√≠veis
/status                  # Status da sess√£o atual
/context                 # Mostra contexto do projeto
/change-model phi-3      # Troca para outro modelo
/clear                   # Limpa hist√≥rico da conversa
/save sessao-importante  # Salva conversa atual
/load sessao-importante  # Carrega conversa salva
/exit                    # Sai do chat
```

### 5. Exemplos de Conversas
```bash
# Exemplo 1: Criar testes
ü§ñ > Crie testes unit√°rios para o componente UserProfile

# A CLI ir√°:
# 1. Analisar o c√≥digo existente
# 2. Gerar testes apropriados
# 3. Pedir confirma√ß√£o antes de aplicar
# 4. Criar backups autom√°ticos

# Exemplo 2: Refatorar c√≥digo
ü§ñ > Converta o componente UserProfile para hooks funcionais

# Exemplo 3: Criar nova funcionalidade
ü§ñ > Crie um sistema de autentica√ß√£o com JWT
```

## üîß Comandos de Desenvolvimento

### 6. Criar Funcionalidades
```bash
# Criar testes
llm create test UserProfile -d "Testes unit√°rios para componente de perfil do usu√°rio"

# Criar m√≥dulo
llm create module auth -d "Sistema de autentica√ß√£o com JWT e refresh tokens"

# Criar componente
llm create component DataTable -d "Tabela de dados com pagina√ß√£o e filtros"

# Criar servi√ßo
llm create service api -d "Servi√ßo para comunica√ß√£o com API REST"
```

### 7. Editar Arquivos
```bash
# Editar arquivo com instru√ß√£o espec√≠fica
llm edit src/components/UserProfile.tsx "Adicione valida√ß√£o de formul√°rio e tratamento de erros"

# Editar arquivo para refatora√ß√£o
llm edit src/services/auth.ts "Converta para usar async/await e adicione tratamento de erros"

# Editar arquivo para otimiza√ß√£o
llm edit src/utils/helpers.ts "Otimize as fun√ß√µes de formata√ß√£o de data e moeda"
```

### 8. Gerenciar Modelos
```bash
# Listar modelos dispon√≠veis
llm list-models

# Trocar modelo do projeto atual
llm change-model -m phi-3:3.8b-instruct

# Ver status do projeto
llm status
```

## üìÅ Gerenciamento de Projetos

### 9. Inicializar Diferentes Tipos de Projeto
```bash
# Projeto React/TypeScript
cd ~/projetos/react-app
llm init

# Projeto Node.js/Express
cd ~/projetos/api-backend
llm init

# Projeto Python/Django
cd ~/projetos/django-app
llm init

# Projeto Go/Gin
cd ~/projetos/go-api
llm init
```

### 10. Configura√ß√µes por Projeto
```bash
# Cada projeto ter√° sua configura√ß√£o em .llm-cli/project.json
{
  "path": "/home/user/projetos/react-app",
  "name": "react-app",
  "language": "TypeScript",
  "framework": "React",
  "model": "deepseek-coder:6.7b-instruct",
  "createdAt": "2024-01-01T00:00:00.000Z",
  "updatedAt": "2024-01-01T00:00:00.000Z"
}
```

## üîÑ Sistema de Rollback

### 11. Desfazer Altera√ß√µes
```bash
# Desfazer √∫ltima altera√ß√£o
llm rollback

# Desfazer m√∫ltiplas altera√ß√µes
llm rollback -n 3

# Ver hist√≥rico de altera√ß√µes
# (dispon√≠vel no comando /status no modo conversacional)
```

### 12. Sistema de Backups
```bash
# Backups s√£o criados automaticamente em .llm-cli/backups/
# Formato: arquivo.timestamp.backup

# Listar backups dispon√≠veis
# (funcionalidade dispon√≠vel via FileManager)

# Restaurar de backup espec√≠fico
# (funcionalidade dispon√≠vel via FileManager)
```

## üéØ Cen√°rios de Uso Comuns

### 13. Desenvolvimento de API
```bash
# 1. Inicializar projeto
cd ~/projetos/api-rest
llm init

# 2. Iniciar chat para desenvolvimento
llm chat

# 3. Solicitar cria√ß√£o de endpoints
ü§ñ > Crie endpoints CRUD para usu√°rios com valida√ß√£o e autentica√ß√£o

# 4. Solicitar testes
ü§ñ > Crie testes de integra√ß√£o para os endpoints de usu√°rios

# 5. Solicitar documenta√ß√£o
ü§ñ > Gere documenta√ß√£o OpenAPI/Swagger para a API
```

### 14. Desenvolvimento Frontend
```bash
# 1. Inicializar projeto React
cd ~/projetos/react-dashboard
llm init

# 2. Solicitar cria√ß√£o de componentes
ü§ñ > Crie um dashboard responsivo com gr√°ficos e tabelas

# 3. Solicitar otimiza√ß√£o
ü§ñ > Otimize o componente de gr√°ficos para melhor performance

# 4. Solicitar testes
ü§ñ > Crie testes para os componentes do dashboard
```

### 15. Refatora√ß√£o de C√≥digo
```bash
# 1. Identificar arquivo para refatorar
llm edit src/legacy/auth.js "Converta para TypeScript e use padr√µes modernos"

# 2. Aplicar mudan√ßas sugeridas
# (a CLI pedir√° confirma√ß√£o)

# 3. Verificar resultado
llm status

# 4. Se necess√°rio, fazer rollback
llm rollback
```

## üîß Configura√ß√µes Avan√ßadas

### 16. Configura√ß√£o MCP
```bash
# Editar ~/.llm-cli/config.json
{
  "mcpConfig": {
    "serverUrl": "http://localhost",
    "port": 8000,
    "protocol": "http",
    "timeout": 30000
  }
}
```

### 17. Configura√ß√£o Ollama
```bash
# Editar ~/.llm-cli/config.json
{
  "ollamaConfig": {
    "modelsPath": "~/.local/share/ollama/models",
    "serverUrl": "http://localhost",
    "port": 11434,
    "maxMemory": 8192,
    "gpuEnabled": true
  }
}
```

## üö® Solu√ß√£o de Problemas

### 18. Problemas Comuns
```bash
# Erro: "Modelo n√£o encontrado"
llm list-models                    # Verificar modelos dispon√≠veis
llm detect-hardware               # Verificar compatibilidade

# Erro: "Falha ao conectar ao servidor MCP"
# Verificar se o servidor MCP est√° rodando
# Verificar configura√ß√£o em ~/.llm-cli/config.json

# Erro: "Hardware n√£o detectado"
llm detect-hardware               # Executar detec√ß√£o manual
# Verificar permiss√µes de sistema

# Erro: "Projeto n√£o inicializado"
llm init                          # Inicializar projeto
# Verificar se est√° na pasta correta
```

### 19. Logs e Debug
```bash
# Ver logs detalhados
# A CLI mostra logs informativos durante opera√ß√µes

# Verificar configura√ß√£o
cat ~/.llm-cli/config.json

# Verificar projeto atual
cat .llm-cli/project.json
```

## üìö Dicas e Melhores Pr√°ticas

### 20. Dicas de Uso
- **Use comandos espec√≠ficos**: Seja claro nas instru√ß√µes para o modelo
- **Confirme mudan√ßas**: Sempre revise as mudan√ßas antes de aplicar
- **Mantenha contexto**: Use o chat para manter contexto entre sess√µes
- **Fa√ßa backups**: O sistema cria backups autom√°ticos, mas mantenha controle de vers√£o
- **Teste modelos**: Experimente diferentes modelos para encontrar o melhor para seu caso

### 21. Fluxo de Trabalho Recomendado
```bash
# 1. Configura√ß√£o inicial
llm detect-hardware
llm set-default-model <modelo-recomendado>

# 2. Por projeto
cd projeto/
llm init
llm chat

# 3. Desenvolvimento iterativo
# - Use chat para discuss√µes e planejamento
# - Use comandos espec√≠ficos para a√ß√µes precisas
# - Revise mudan√ßas antes de aplicar
# - Use rollback quando necess√°rio

# 4. Manuten√ß√£o
llm status                    # Verificar status
llm list-models              # Verificar modelos
# Limpar conversas antigas periodicamente
```

---

**üí° Dica**: A LLM CLI √© mais eficaz quando voc√™ combina o modo conversacional para discuss√µes e comandos espec√≠ficos para a√ß√µes precisas. Use o chat para entender o contexto e os comandos para executar mudan√ßas espec√≠ficas.
